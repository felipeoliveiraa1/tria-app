import { useCallback, useRef, useState, useEffect } from 'react'
import { Room, RoomEvent, Track, LocalAudioTrack } from 'livekit-client'
import { useRecordingStore } from '../store/recording-store'
import { createVADNode, VADMessage } from '@/audio/vad-node'
import { SpeechSegmenter, SpeechSegment } from '@/audio/speech-segmenter'
import { makeMultipart } from '@/audio/audio-utils'

interface DualLiveKitSTTConfig {
  consultationId: string
  livekitUrl?: string
}

type DeviceOption = { deviceId: string; label: string }

type MicrophoneConfig = {
  deviceId: string
  speaker: 'doctor' | 'patient'
  label: string
}

export function useDualLivekitSTT(config: DualLiveKitSTTConfig) {
  const [isConnected, setIsConnected] = useState(false)
  const [isConnecting, setIsConnecting] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [participants, setParticipants] = useState<string[]>([])
  const [devices, setDevices] = useState<DeviceOption[]>([])
  const [doctorMic, setDoctorMic] = useState<string>('')
  const [patientMic, setPatientMic] = useState<string>('')
  
  const roomRef = useRef<Room | null>(null)
  const eventSourceRef = useRef<EventSource | null>(null)
  const doctorRecorderRef = useRef<MediaRecorder | null>(null)
  const patientRecorderRef = useRef<MediaRecorder | null>(null)
  const doctorChunksRef = useRef<Blob[]>([])
  const patientChunksRef = useRef<Blob[]>([])
  const processingRef = useRef<{ doctor: boolean; patient: boolean }>({ doctor: false, patient: false })
  const reconnectTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const doctorIntervalRef = useRef<NodeJS.Timeout | null>(null)
  const patientIntervalRef = useRef<NodeJS.Timeout | null>(null)
  const doctorTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const patientTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const lastActivityRef = useRef<number>(Date.now())
  const isReconnectingRef = useRef(false)
  const doctorStreamRef = useRef<MediaStream | null>(null)
  const patientStreamRef = useRef<MediaStream | null>(null)
  const lastTranscriptionRef = useRef<{doctor: string | undefined, patient: string | undefined}>({doctor: undefined, patient: undefined})
  const processedTranscriptionsRef = useRef<Set<string>>(new Set())
  
  // VAD e Speech Segmentation
  const doctorVADRef = useRef<any>(null)
  const patientVADRef = useRef<any>(null)
  const doctorSegmenterRef = useRef<SpeechSegmenter | null>(null)
  const patientSegmenterRef = useRef<SpeechSegmenter | null>(null)
  const doctorAudioContextRef = useRef<AudioContext | null>(null)
  const patientAudioContextRef = useRef<AudioContext | null>(null)
  
  // Floor control
  const doctorActiveRef = useRef(false)
  const patientActiveRef = useRef(false)
  const doctorFloorHoldRef = useRef(0)
  const patientFloorHoldRef = useRef(0)
  
  const { 
    addFinalSegment, 
    setRealtimeConnected,
    setConsultationId 
  } = useRecordingStore()

  // Detectar microfone ativo baseado no √°udio
  const detectActiveMicrophone = useCallback((audioData: Float32Array, speaker: 'doctor' | 'patient') => {
    // Calcular volume m√©dio
    const volume = audioData.reduce((sum, sample) => sum + Math.abs(sample), 0) / audioData.length
    
    // Se o volume for alto o suficiente, considerar ativo
    const isActive = volume > 0.01 // Threshold ajust√°vel
    
    if (isActive) {
      console.log(`üé§ Microfone ${speaker} ativo - Volume: ${volume.toFixed(4)}`)
    }
    
    return isActive
  }, [])

  // Fun√ß√£o espec√≠fica para bloquear conte√∫do de v√≠deo/legendas
  const isVideoContent = useCallback((text: string) => {
    const videoPatterns = [
      /amara/i,
      /comunidade/i,
      /legendas/i,
      /\.org/i,
      /subtitle/i,
      /caption/i,
      /transcri√ß√£o autom√°tica/i,
      /legendas autom√°ticas/i,
      /legendas geradas/i,
      /legendas pela/i,
      /legendas pela comunidade/i,
      /amara\.org/i,
    ]
    
    return videoPatterns.some(pattern => pattern.test(text))
  }, [])

  // Verificar se o texto tem contexto m√©dico real
  const hasMedicalContext = useCallback((text: string) => {
    // Primeiro, verificar se cont√©m conte√∫do de v√≠deo/legendas
    if (isVideoContent(text)) {
      return false // Bloquear completamente
    }
    
    const medicalKeywords = [
      // Sintomas comuns
      'dor', 'dores', 'dolorido', 'dolorida',
      'febre', 'temperatura', 'calafrio',
      'tosse', 'tossindo', 'tossir',
      'nariz', 'coriza', 'espirro',
      'garganta', 'rouquid√£o', 'rouco',
      'cabe√ßa', 'enxaqueca', 'tontura',
      'est√¥mago', 'barriga', 'abd√¥men',
      'n√°usea', 'v√¥mito', 'diarreia',
      'cansa√ßo', 'fadiga', 'fraqueza',
      'falta de ar', 'respira√ß√£o', 'respirar',
      'peito', 'cora√ß√£o', 'palpita√ß√£o',
      'press√£o', 'hipertens√£o', 'hipotens√£o',
      'diabetes', 'glicemia', 'a√ß√∫car',
      'colesterol', 'triglicer√≠deos',
      'peso', 'emagrecer', 'engordar',
      'altura', 'crescimento',
      'sangue', 'hemorragia', 'sangramento',
      'urina', 'xixi', 'bexiga',
      'fezes', 'coc√¥', 'intestino',
      'pele', 'mancha', 'verruga', 'espinha',
      'olho', 'vis√£o', 'enxergar',
      'ouvido', 'audi√ß√£o', 'escutar',
      'dente', 'gengiva', 'boca',
      'm√∫sculo', 'osso', 'articula√ß√£o',
      'joelho', 'tornozelo', 'ombro',
      'pesco√ßo', 'costas', 'coluna',
      'bra√ßo', 'perna', 'm√£o', 'p√©',
      
      // Medicamentos
      'rem√©dio', 'medicamento', 'comprimido',
      'c√°psula', 'xarope', 'gotas',
      'pomada', 'creme', 'gel',
      'inje√ß√£o', 'seringa', 'agulha',
      'antibi√≥tico', 'anti-inflamat√≥rio',
      'analg√©sico', 'antit√©rmico',
      'vitamina', 'suplemento',
      
      // Exames
      'exame', 'teste', 'an√°lise',
      'sangue', 'urina', 'fezes',
      'raio x', 'ultrassom', 'tomografia',
      'resson√¢ncia', 'ecocardiograma',
      'eletrocardiograma', 'ecg',
      'endoscopia', 'colonoscopia',
      'mamografia', 'papanicolau',
      'bi√≥psia', 'citologia',
      
      // Especialidades m√©dicas
      'cl√≠nico', 'pediatra', 'ginecologista',
      'cardiologista', 'neurologista',
      'ortopedista', 'dermatologista',
      'oftalmologista', 'otorrino',
      'psiquiatra', 'psic√≥logo',
      'fisioterapeuta', 'nutricionista',
      
      // Condi√ß√µes m√©dicas
      'gripe', 'resfriado', 'sinusite',
      'bronquite', 'pneumonia', 'asma',
      'hipertens√£o', 'diabetes', 'obesidade',
      'ansiedade', 'depress√£o', 'estresse',
      'ins√¥nia', 'apneia', 'ronco',
      'alergia', 'asma', 'rinite',
      'gastrite', '√∫lcera', 'refluxo',
      'hepatite', 'cirrose', 'pedra',
      'c√°lculo', 'cistite', 'infec√ß√£o',
      'inflama√ß√£o', 'tumor', 'c√¢ncer',
      'met√°stase', 'quimioterapia',
      'radioterapia', 'cirurgia',
      
      // Partes do corpo
      'cabe√ßa', 'pesco√ßo', 'ombro',
      'bra√ßo', 'cotovelo', 'punho',
      'm√£o', 'dedo', 'peito',
      'costas', 'coluna', 'lombar',
      'quadril', 'perna', 'joelho',
      'tornozelo', 'p√©', 'calcanhar',
      'olho', 'orelha', 'nariz',
      'boca', 'dente', 'l√≠ngua',
      'garganta', 'pesco√ßo', 'tireoide',
      'pulm√£o', 'cora√ß√£o', 'f√≠gado',
      'rim', 'bexiga', 'intestino',
      'est√¥mago', 'p√¢ncreas', 'ba√ßo',
      '√∫tero', 'ov√°rio', 'pr√≥stata',
      'test√≠culo', 'p√™nis', 'vagina',
      'mama', 'pele', 'unha', 'cabelo',
      
      // Palavras de contexto m√©dico geral
      'paciente', 'm√©dico', 'doutor', 'doutora',
      'consulta', 'atendimento', 'tratamento',
      'diagn√≥stico', 'sintoma', 'sintomas',
      'hist√≥rico', 'cl√≠nico', 'anamnese',
      'idade', 'anos', 'meses', 'dias',
      'nome', 'endere√ßo', 'telefone',
      'alergia', 'alergias', 'medicamento',
      'medicamentos', 'dosagem', 'posologia',
      'hor√°rio', 'manh√£', 'tarde', 'noite',
      'comer', 'beber', 'dormir', 'acordar',
      'sentir', 'sentindo', 'melhor', 'pior',
      'dor', 'dores', 'inc√¥modo', 'desconforto',
      'faz', 'fazer', 'tomar', 'usar',
      'aplicar', 'colocar', 'retirar',
      'voltar', 'retorno', 'pr√≥xima',
      'agendar', 'marcar', 'cancelar',
      'receita', 'atestado', 'exame',
      'resultado', 'laudo', 'prontu√°rio'
    ]
    
    const normalizedText = text.toLowerCase()
    
    // Verificar se cont√©m pelo menos uma palavra-chave m√©dica
    const hasKeyword = medicalKeywords.some(keyword => 
      normalizedText.includes(keyword)
    )
    
    // Verificar se tem pelo menos 5 caracteres (texto substancial)
    const hasSubstance = normalizedText.length >= 5
    
    // Verificar se n√£o √© apenas pontua√ß√£o ou espa√ßos
    const hasContent = /[a-zA-Z]/.test(normalizedText)
    
    // Se tem palavra-chave m√©dica, aceita
    if (hasKeyword && hasSubstance && hasContent) {
      return true
    }
    
    // Se n√£o tem palavra-chave m√©dica, mas tem pelo menos 15 caracteres e parece ser uma frase real, aceita
    if (hasSubstance && hasContent && normalizedText.length >= 15 && 
        (normalizedText.includes(' ') || normalizedText.includes(',') || normalizedText.includes('.'))) {
      return true
    }
    
    return false
  }, [])

  // Filtrar transcri√ß√µes gen√©ricas e de baixa qualidade
  const isGenericTranscription = useCallback((text: string) => {
    // Filtro agressivo para legendas e conte√∫do de v√≠deo
    if (isVideoContent(text)) {
      return true
    }
    const genericPatterns = [
      // Padr√µes gen√©ricos de consulta m√©dica
      /o paciente est√° falando com o m√©dico/i,
      /sobre seus sintomas e hist√≥rico m√©dico/i,
      /consulta m√©dica/i,
      /sintomas e hist√≥rico/i,
      /m√©dico sobre seus/i,
      /paciente est√° falando/i,
      /hist√≥rico m√©dico/i,
      /sintomas e hist√≥rico m√©dico/i,
      
      // Padr√µes gen√©ricos comuns que n√£o fazem sentido
      /como foi/i,
      /agora eu vou na horticultura/i,
      /cade a√ß√£o/i,
      /√© isso a√≠/i,
      /muito obrigado/i,
      /obrigado/i,
      /obrigada/i,
      /obrigado\./i,
      /obrigada\./i,
      /para a verdade/i,
      /a verdade √© que voc√™/i,
      /est√° com um leve delayzinho/i,
      /acho que esse pa√≠s tem sempre sido mais desagrad√°vel/i,
      /o paciente testificado s√≥ teve uma musclesose/i,
      /tiroside –¥–∞–≤—ñnho/i,
      /quest√µes exigentes do oxig√™nio/i,
      /alguma sensa√ß√£o sobre o oxig√™nio/i,
      /harry de outro vez/i,
      
      // Padr√µes de legendas e transcri√ß√µes autom√°ticas
      /legendas pela comunidade/i,
      /amara\.org/i,
      /legendas autom√°ticas/i,
      /transcri√ß√£o autom√°tica/i,
      /legendas geradas automaticamente/i,
      /subtitle/i,
      /caption/i,
      /legendas/i,
      /comunidade/i,
      /amara/i,
      /\.org/i,
      /a gente vai editar na informa√ß√£o/i,
      /pra gente enxugar melhor/i,
      /como voc√™ est√°/i,
      /bom dia/i,
      /boa tarde/i,
      /boa noite/i,
      /tudo bem/i,
      /como vai/i,
      /est√° tudo certo/i,
      /vou prescrever/i,
      /vou receitar/i,
      /tome este medicamento/i,
      /volte em/i,
      /agende uma consulta/i,
      /exame de sangue/i,
      /raio x/i,
      /ultrassom/i,
      /tomografia/i,
      /resson√¢ncia magn√©tica/i,
      /bi√≥psia/i,
      /cirurgia/i,
      /interna√ß√£o/i,
      /alta m√©dica/i,
      /atestado m√©dico/i,
      /receita m√©dica/i,
      /laudo m√©dico/i,
      /prontu√°rio m√©dico/i,
      /hist√≥rico cl√≠nico/i,
      /anamnese/i,
      /diagn√≥stico/i,
      /tratamento/i,
      /medicamento/i,
      /dosagem/i,
      /posologia/i,
      /efeitos colaterais/i,
      /contraindica√ß√µes/i,
      /alergia/i,
      /rea√ß√£o al√©rgica/i,
      /press√£o arterial/i,
      /frequ√™ncia card√≠aca/i,
      /temperatura/i,
      /peso/i,
      /altura/i,
      /imc/i,
      /√≠ndice de massa corporal/i,
      /glicemia/i,
      /colesterol/i,
      /triglicer√≠deos/i,
      /hemoglobina/i,
      /leuc√≥citos/i,
      /plaquetas/i,
      /urina/i,
      /fezes/i,
      /sangue/i,
      /muco/i,
      /secre√ß√£o/i,
      /inflama√ß√£o/i,
      /infec√ß√£o/i,
      /bact√©ria/i,
      /v√≠rus/i,
      /fungo/i,
      /parasita/i,
      /antibi√≥tico/i,
      /anti-inflamat√≥rio/i,
      /analg√©sico/i,
      /antit√©rmico/i,
      /antial√©rgico/i,
      /antidepressivo/i,
      /ansiol√≠tico/i,
      /son√≠fero/i,
      /vitamina/i,
      /suplemento/i,
      /fitoter√°pico/i,
      /homeopatia/i,
      /acupuntura/i,
      /fisioterapia/i,
      /terapia ocupacional/i,
      /psicologia/i,
      /psiquiatria/i,
      /cardiologia/i,
      /neurologia/i,
      /ortopedia/i,
      /dermatologia/i,
      /ginecologia/i,
      /urologia/i,
      /pediatria/i,
      /geriatria/i,
      /oncologia/i,
      /hematologia/i,
      /endocrinologia/i,
      /gastroenterologia/i,
      /pneumologia/i,
      /reumatologia/i,
      /oftalmologia/i,
      /otorrinolaringologia/i,
      /cirurgia geral/i,
      /cirurgia pl√°stica/i,
      /cirurgia card√≠aca/i,
      /cirurgia neurol√≥gica/i,
      /cirurgia ortop√©dica/i,
      /cirurgia vascular/i,
      /cirurgia digestiva/i,
      /cirurgia urol√≥gica/i,
      /cirurgia ginecol√≥gica/i,
      /cirurgia pedi√°trica/i,
      /cirurgia tor√°cica/i,
      /cirurgia de cabe√ßa e pesco√ßo/i,
      /cirurgia de m√£o/i,
      /cirurgia de coluna/i,
      /cirurgia de joelho/i,
      /cirurgia de quadril/i,
      /cirurgia de ombro/i,
      /cirurgia de tornozelo/i,
      /cirurgia de p√©/i,
      /cirurgia de retina/i,
      /cirurgia de catarata/i,
      /cirurgia de glaucoma/i,
      /cirurgia de estrabismo/i,
      /cirurgia de p√°lpebra/i,
      /cirurgia de nariz/i,
      /cirurgia de ouvido/i,
      /cirurgia de garganta/i,
      /cirurgia de tireoide/i,
      /cirurgia de paratireoide/i,
      /cirurgia de adrenal/i,
      /cirurgia de p√¢ncreas/i,
      /cirurgia de f√≠gado/i,
      /cirurgia de ves√≠cula/i,
      /cirurgia de ba√ßo/i,
      /cirurgia de rim/i,
      /cirurgia de bexiga/i,
      /cirurgia de pr√≥stata/i,
      /cirurgia de √∫tero/i,
      /cirurgia de ov√°rio/i,
      /cirurgia de mama/i,
      /cirurgia de pulm√£o/i,
      /cirurgia de cora√ß√£o/i,
      /cirurgia de aorta/i,
      /cirurgia de art√©ria/i,
      /cirurgia de veia/i,
      /cirurgia de nervo/i,
      /cirurgia de tend√£o/i,
      /cirurgia de ligamento/i,
      /cirurgia de menisco/i,
      /cirurgia de cartilagem/i,
      /cirurgia de osso/i,
      /cirurgia de fratura/i,
      /cirurgia de luxa√ß√£o/i,
      /cirurgia de entorse/i,
      /cirurgia de contus√£o/i,
      /cirurgia de hematoma/i,
      /cirurgia de abscesso/i,
      /cirurgia de cisto/i,
      /cirurgia de n√≥dulo/i,
      /cirurgia de tumor/i,
      /cirurgia de c√¢ncer/i,
      /cirurgia de met√°stase/i,
      /cirurgia de recidiva/i,
      /cirurgia de remiss√£o/i,
      /cirurgia de cura/i,
      /cirurgia de sobrevida/i,
      /cirurgia de qualidade de vida/i,
      /cirurgia de reabilita√ß√£o/i,
      /cirurgia de recupera√ß√£o/i,
      /cirurgia de cicatriza√ß√£o/i,
      /cirurgia de infec√ß√£o/i,
      /cirurgia de complica√ß√£o/i,
      /cirurgia de risco/i,
      /cirurgia de benef√≠cio/i,
      /cirurgia de indica√ß√£o/i,
      /cirurgia de contraindica√ß√£o/i,
      /cirurgia de alternativa/i,
      /cirurgia de op√ß√£o/i,
      /cirurgia de escolha/i,
      /cirurgia de decis√£o/i,
      /cirurgia de consentimento/i,
      /cirurgia de autoriza√ß√£o/i,
      /cirurgia de libera√ß√£o/i,
      /cirurgia de alta/i,
      /cirurgia de interna√ß√£o/i,
      /cirurgia de pr√©-operat√≥rio/i,
      /cirurgia de p√≥s-operat√≥rio/i,
      /cirurgia de anestesia/i,
      /cirurgia de seda√ß√£o/i,
      /cirurgia de monitoramento/i,
      /cirurgia de acompanhamento/i,
      /cirurgia de seguimento/i,
      /cirurgia de retorno/i,
      /cirurgia de consulta/i,
      /cirurgia de exame/i,
      /cirurgia de teste/i,
      /cirurgia de avalia√ß√£o/i,
      /cirurgia de diagn√≥stico/i,
      /cirurgia de tratamento/i,
      /cirurgia de terapia/i,
      /cirurgia de medicamento/i,
      /cirurgia de dosagem/i,
      /cirurgia de posologia/i,
      /cirurgia de efeitos colaterais/i,
      /cirurgia de contraindica√ß√µes/i,
      /cirurgia de alergia/i,
      /cirurgia de rea√ß√£o al√©rgica/i,
      /cirurgia de press√£o arterial/i,
      /cirurgia de frequ√™ncia card√≠aca/i,
      /cirurgia de temperatura/i,
      /cirurgia de peso/i,
      /cirurgia de altura/i,
      /cirurgia de imc/i,
      /cirurgia de √≠ndice de massa corporal/i,
      /cirurgia de glicemia/i,
      /cirurgia de colesterol/i,
      /cirurgia de triglicer√≠deos/i,
      /cirurgia de hemoglobina/i,
      /cirurgia de leuc√≥citos/i,
      /cirurgia de plaquetas/i,
      /cirurgia de urina/i,
      /cirurgia de fezes/i,
      /cirurgia de sangue/i,
      /cirurgia de muco/i,
      /cirurgia de secre√ß√£o/i,
      /cirurgia de inflama√ß√£o/i,
      /cirurgia de infec√ß√£o/i,
      /cirurgia de bact√©ria/i,
      /cirurgia de v√≠rus/i,
      /cirurgia de fungo/i,
      /cirurgia de parasita/i,
      /cirurgia de antibi√≥tico/i,
      /cirurgia de anti-inflamat√≥rio/i,
      /cirurgia de analg√©sico/i,
      /cirurgia de antit√©rmico/i,
      /cirurgia de antial√©rgico/i,
      /cirurgia de antidepressivo/i,
      /cirurgia de ansiol√≠tico/i,
      /cirurgia de son√≠fero/i,
      /cirurgia de vitamina/i,
      /cirurgia de suplemento/i,
      /cirurgia de fitoter√°pico/i,
      /cirurgia de homeopatia/i,
      /cirurgia de acupuntura/i,
      /cirurgia de fisioterapia/i,
      /cirurgia de terapia ocupacional/i,
      /cirurgia de psicologia/i,
      /cirurgia de psiquiatria/i,
      /cirurgia de cardiologia/i,
      /cirurgia de neurologia/i,
      /cirurgia de ortopedia/i,
      /cirurgia de dermatologia/i,
      /cirurgia de ginecologia/i,
      /cirurgia de urologia/i,
      /cirurgia de pediatria/i,
      /cirurgia de geriatria/i,
      /cirurgia de oncologia/i,
      /cirurgia de hematologia/i,
      /cirurgia de endocrinologia/i,
      /cirurgia de gastroenterologia/i,
      /cirurgia de pneumologia/i,
      /cirurgia de reumatologia/i,
      /cirurgia de oftalmologia/i,
      /cirurgia de otorrinolaringologia/i,
      
      // Padr√µes de transcri√ß√£o vazia ou gen√©rica
      /^[.\s]*$/,
      /^[.,!?;:\s]*$/,
      /^[a-z\s]{1,10}$/i, // Textos muito curtos
      /^[^a-zA-Z]*$/, // Apenas pontua√ß√£o
      
      // Padr√µes de ru√≠do
      /^[hm]+$/i,
      /^[ah]+$/i,
      /^[eh]+$/i,
      /^[uh]+$/i,
      /^[oh]+$/i,
      
      // Padr√µes repetitivos
      /^(.+)\1{2,}$/, // Texto repetido 3+ vezes
    ]
    
    const normalizedText = text.trim().toLowerCase()
    
    // Verificar se √© muito curto
    if (normalizedText.length < 3) {
      return true
    }
    
    // Verificar padr√µes gen√©ricos
    for (const pattern of genericPatterns) {
      if (pattern.test(normalizedText)) {
        return true
      }
    }
    
    return false
  }, [])

  // Verificar se duas transcri√ß√µes s√£o muito similares
  const isSimilarTranscription = useCallback((text1: string, text2: string) => {
    if (!text1 || !text2) return false
    
    const normalized1 = text1.trim().toLowerCase()
    const normalized2 = text2.trim().toLowerCase()
    
    // Se s√£o exatamente iguais
    if (normalized1 === normalized2) return true
    
    // Calcular similaridade simples (percentual de palavras em comum)
    const words1 = normalized1.split(/\s+/)
    const words2 = normalized2.split(/\s+/)
    
    if (words1.length < 3 || words2.length < 3) return false
    
    const commonWords = words1.filter(word => words2.includes(word))
    const similarity = commonWords.length / Math.max(words1.length, words2.length)
    
    // Se mais de 80% das palavras s√£o iguais, considerar similar
    return similarity > 0.8
  }, [])

  // Fun√ß√£o para detectar textos repetitivos ou autom√°ticos
  const isRepetitiveText = useCallback((text: string): boolean => {
    // Primeiro, verificar se cont√©m conte√∫do de v√≠deo/legendas
    if (isVideoContent(text)) {
      return true
    }
    
    const cleanText = text.toLowerCase().trim()
    
    // Padr√µes de texto repetitivo
    const repetitivePatterns = [
      /^(n√£o!?\s*){3,}/i, // "n√£o n√£o n√£o"
      /^(sim!?\s*){3,}/i, // "sim sim sim"
      /^(\w+!?\s*)\1{2,}/i, // qualquer palavra repetida 3x
      /^(ok|okay|t√°|certo|uhum)\s*$/i, // palavras muito curtas/autom√°ticas
      /^[.!?]{2,}$/, // s√≥ pontua√ß√£o
    ]
    
    if (repetitivePatterns.some(pattern => pattern.test(cleanText))) {
      return true
    }
    
    // Verificar repeti√ß√£o excessiva de palavras
    const words = cleanText.split(/\s+/)
    if (words.length >= 3) {
      const wordCount = words.reduce((acc, word) => {
        acc[word] = (acc[word] || 0) + 1
        return acc
      }, {} as Record<string, number>)
      
      const maxFrequency = Math.max(...Object.values(wordCount))
      if (maxFrequency / words.length > 0.6) { // Se uma palavra aparece mais de 60%
        return true
      }
    }
    
    return false
  }, [])

  // Carregar dispositivos de √°udio dispon√≠veis
  const loadDevices = useCallback(async () => {
    try {
      console.log('üé§ Carregando dispositivos de √°udio...')
      
      // Solicitar permiss√£o primeiro
      await navigator.mediaDevices.getUserMedia({ audio: true })
      
      const deviceList = await navigator.mediaDevices.enumerateDevices()
      const microphones = deviceList
        .filter(device => device.kind === 'audioinput')
        .map(device => ({
          deviceId: device.deviceId,
          label: device.label || `Microfone ${device.deviceId.substring(0, 8)}`
        }))
      
      setDevices(microphones)
      console.log('üé§ Dispositivos encontrados:', microphones.length)
      
      // Definir dispositivos padr√£o se n√£o houver sele√ß√£o
      if (!doctorMic && microphones.length > 0) {
        setDoctorMic(microphones[0].deviceId)
        console.log('ü©∫ Microfone padr√£o do m√©dico:', microphones[0].label)
      }
      
      if (!patientMic && microphones.length > 1) {
        setPatientMic(microphones[1].deviceId)
        console.log('üßë‚Äç‚öïÔ∏è Microfone padr√£o do paciente:', microphones[1].label)
      } else if (!patientMic && microphones.length === 1) {
        // Se s√≥ h√° um microfone, usar o mesmo para ambos (com processamento diferente)
        setPatientMic(microphones[0].deviceId)
        console.log('‚ö†Ô∏è Usando mesmo microfone para ambos (ser√° separado por volume)')
      }
      
      return microphones
    } catch (error) {
      console.error('‚ùå Erro ao carregar dispositivos:', error)
      setError('Erro ao acessar dispositivos de √°udio')
      return []
    }
  }, [doctorMic, patientMic])

  // Processar chunk de √°udio para transcri√ß√£o
  const processAudioChunk = useCallback(async (audioBlob: Blob, speaker: 'doctor' | 'patient') => {
    if (processingRef.current[speaker]) {
      console.log(`‚è© Pulando processamento ${speaker} - j√° em andamento`)
      return
    }
    
    if (audioBlob.size < 5000) {
      console.log(`‚è© Pulando chunk ${speaker} - muito pequeno (${audioBlob.size} bytes)`)
      return // Pular chunks muito pequenos
    }
    
    if (audioBlob.size > 1000000) {
      console.log(`‚è© Pulando chunk ${speaker} - muito grande (${audioBlob.size} bytes)`)
      return // Pular chunks muito grandes
    }
    
    if (!audioBlob.type.startsWith('audio/')) {
      console.log(`‚ùå Tipo de arquivo inv√°lido para ${speaker}: ${audioBlob.type}`)
      return
    }

    try {
      processingRef.current[speaker] = true
      lastActivityRef.current = Date.now() // Atualizar atividade
      
      console.log(`üé§ ENVIANDO CHUNK PARA TRANSCRI√á√ÉO (${speaker}):`, {
        size: audioBlob.size,
        type: audioBlob.type,
        duration: audioBlob.size / 16000 // Estimativa de dura√ß√£o
      })

      // Filtrar chunks muito pequenos que podem ser ru√≠do
      if (audioBlob.size < 20000) { // Menos de 20KB (aumentado)
        console.log(`‚è© PULANDO CHUNK ${speaker} - muito pequeno (${audioBlob.size} bytes)`)
        return
      }

      // Detectar se o √°udio tem volume suficiente (n√£o √© sil√™ncio)
      try {
        const arrayBuffer = await audioBlob.arrayBuffer()
        const audioContext = new AudioContext()
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer)
        
        // Calcular volume m√©dio do √°udio
        const channelData = audioBuffer.getChannelData(0)
        let sum = 0
        for (let i = 0; i < channelData.length; i++) {
          sum += Math.abs(channelData[i])
        }
        const averageVolume = sum / channelData.length
        
        console.log(`üîä VOLUME DETECTADO (${speaker}):`, averageVolume)
        
        // Se o volume for muito baixo, √© provavelmente sil√™ncio
        if (averageVolume < 0.01) { // Threshold de volume
          console.log(`üîá PULANDO CHUNK ${speaker} - volume muito baixo (${averageVolume})`)
          return
        }
        
        await audioContext.close()
      } catch (error) {
        console.warn('Erro ao analisar volume do √°udio:', error)
      }

      // Detectar se o microfone est√° ativo (opcional - para debug)
      // const audioContext = new AudioContext()
      // const arrayBuffer = await audioBlob.arrayBuffer()
      // const audioBuffer = await audioContext.decodeAudioData(arrayBuffer)
      // const audioData = audioBuffer.getChannelData(0)
      // const isActive = detectActiveMicrophone(audioData, speaker)
      
      // Enviar para API de transcri√ß√£o real com timeout
      const formData = new FormData()
      formData.append('audio', audioBlob, 'audio.webm')
      formData.append('speaker', speaker)
      formData.append('consultationId', config.consultationId)

      const controller = new AbortController()
      const timeoutId = setTimeout(() => {
        console.log(`‚è∞ Timeout de 30s atingido para ${speaker}, cancelando requisi√ß√£o...`)
        controller.abort()
      }, 30000) // 30s timeout - mais tempo para OpenAI processar
      
      // Armazenar refer√™ncia do timeout para limpeza
      const timeoutRef = speaker === 'doctor' ? doctorTimeoutRef : patientTimeoutRef
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current)
      }
      timeoutRef.current = timeoutId

      try {
        // Enviando requisi√ß√£o de transcri√ß√£o
        const response = await fetch('/api/transcribe', {
          method: 'POST',
          body: formData,
          signal: controller.signal
        })

        clearTimeout(timeoutId)
        // Resposta recebida

        if (response.ok) {
          const result = await response.json()
          console.log(`üì° RESPOSTA DA API OPENAI (${speaker}):`, {
            text: result.text,
            success: result.success,
            mock: result.mock,
            filtered: result.filtered,
            confidence: result.confidence
          })
          
          // Verificar se a resposta √© v√°lida
          if (!result.success) {
            // Resposta com erro
            return
          }
          
          if (result.mock) {
            // Resposta mock ignorada
            return
          }
          
          if (result.filtered) {
            // Resposta filtrada ignorada
            return
          }
          
          if (result.text && result.text.trim()) {
            // Transcri√ß√£o processada
            
            // Filtro ULTRA agressivo para bloquear conte√∫do de v√≠deo
            if (isVideoContent(result.text)) {
              console.log('üö´ CONTE√öDO DE V√çDEO BLOQUEADO:', result.text)
              return
            }
            
            // Filtrar transcri√ß√µes gen√©ricas e de baixa qualidade
            if (isGenericTranscription(result.text)) {
              console.log('üö´ TRANSCRI√á√ÉO GEN√âRICA FILTRADA:', result.text)
              return
            }
            
            // Verificar confian√ßa m√≠nima
            const confidence = result.confidence || 0.9
            if (confidence < 0.7) {
              // Transcri√ß√£o com baixa confian√ßa filtrada
              return
            }
            
            // Verificar se o texto tem contexto m√©dico real
            if (!hasMedicalContext(result.text)) {
              console.log('üö´ SEM CONTEXTO M√âDICO FILTRADA:', result.text)
              return
            }
            
            // Verificar se √© duplicata ou muito similar √† √∫ltima transcri√ß√£o
            const lastText = lastTranscriptionRef.current[speaker]
            if (lastText && isSimilarTranscription(result.text, lastText)) {
              // Transcri√ß√£o similar/duplicada filtrada
              return
            }
            
            // Verificar se j√° processamos esta transcri√ß√£o exata
            const transcriptionKey = `${speaker}:${result.text}:${Date.now()}`
            if (processedTranscriptionsRef.current.has(result.text)) {
              // Transcri√ß√£o duplicada ignorada
              return
            }
            
            // ‚úÖ Transcri√ß√£o aceita - adicionar ao store
            // Transcri√ß√£o aceita
            
            // Adicionar ao conjunto de transcri√ß√µes processadas
            processedTranscriptionsRef.current.add(result.text)
            
            // Limitar o tamanho do conjunto para evitar vazamento de mem√≥ria
            if (processedTranscriptionsRef.current.size > 100) {
              const firstItem = processedTranscriptionsRef.current.values().next().value
              if (firstItem) {
                processedTranscriptionsRef.current.delete(firstItem)
              }
            }
            
            // Filtrar textos repetitivos e autom√°ticos
            if (isRepetitiveText(result.text)) {
              console.log(`üö´ Texto repetitivo filtrado no processamento (${speaker}):`, result.text)
              return
            }
            
            // Verificar se √© muito similar √† √∫ltima transcri√ß√£o
            const lastSpeakerText = lastTranscriptionRef.current[speaker]
            if (lastSpeakerText && isSimilarTranscription(result.text, lastSpeakerText)) {
              console.log(`üö´ Texto similar filtrado no processamento (${speaker}):`, result.text)
              return
            }
            
            // Atualizar √∫ltima transcri√ß√£o
            lastTranscriptionRef.current[speaker] = result.text
            
            // Adicionar segmento final ao store com informa√ß√£o do speaker
            addFinalSegment({
              text: result.text,
              startMs: 0,
              endMs: 3000, // 3 segundos por chunk
              confidence: confidence,
              isPartial: false,
              speaker: speaker // Incluir informa√ß√£o do speaker
            })
            
            // Segmento adicionado ao store
          }
        } else {
          console.error(`‚ùå Erro na API de transcri√ß√£o ${speaker}:`, response.status, response.statusText)
        }
      } catch (fetchError) {
        clearTimeout(timeoutId)
        if (fetchError instanceof Error && fetchError.name === 'AbortError') {
          console.warn(`‚è∞ Requisi√ß√£o cancelada para ${speaker} - Timeout de 30s atingido`)
          // Tentar novamente com timeout menor se for abort por timeout
          console.log(`üîÑ Tentando novamente ${speaker} com chunk menor...`)
          // N√£o re-throw o erro de abort, apenas log
        } else {
          console.error(`‚ùå Erro na requisi√ß√£o de transcri√ß√£o ${speaker}:`, fetchError)
          // N√£o re-throw outros erros tamb√©m para evitar quebrar o fluxo
        }
      }

    } catch (error) {
      console.error(`‚ùå Erro ao processar chunk de √°udio ${speaker}:`, error)
    } finally {
      processingRef.current[speaker] = false
    }
  }, [config.consultationId])

  // Conectar ao SSE para receber transcri√ß√µes em tempo real
  const connectSSE = useCallback(() => {
    if (eventSourceRef.current) {
      console.log('‚ö†Ô∏è SSE j√° conectado')
      return
    }

    console.log('üîÑ Conectando ao SSE para transcri√ß√µes em tempo real...')
    
    const eventSource = new EventSource(`/api/transcriptions/stream?consultationId=${config.consultationId}`)
    eventSourceRef.current = eventSource

    eventSource.onopen = () => {
      console.log('‚úÖ SSE conectado')
      setRealtimeConnected(true)
      lastActivityRef.current = Date.now()
    }

    eventSource.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data)
        lastActivityRef.current = Date.now()

        if (data.type === 'transcription') {
          console.log(`üìù Transcri√ß√£o recebida via SSE (${data.speaker}):`, data.text)
          
          // Filtrar textos repetitivos e autom√°ticos
          if (isRepetitiveText(data.text)) {
            console.log('üö´ Texto repetitivo filtrado via SSE:', data.text)
            return
          }
          
          // Verificar se √© muito similar √† √∫ltima transcri√ß√£o
          const lastSpeakerText = lastTranscriptionRef.current[data.speaker as 'doctor' | 'patient']
          if (lastSpeakerText && isSimilarTranscription(data.text, lastSpeakerText)) {
            console.log('üö´ Texto similar filtrado via SSE:', data.text)
            return
          }
          
          // Atualizar √∫ltima transcri√ß√£o
          lastTranscriptionRef.current[data.speaker as 'doctor' | 'patient'] = data.text
          
          // Adicionar segmento final ao store com informa√ß√£o do speaker
          addFinalSegment({
            text: data.text,
            startMs: 0,
            endMs: 3000, // 3 segundos por chunk
            confidence: data.confidence,
            isPartial: false,
            speaker: data.speaker // Incluir informa√ß√£o do speaker
          })
        } else if (data.type === 'connected') {
          console.log('üîó SSE conectado para consulta:', data.consultationId)
        } else if (data.type === 'heartbeat') {
          // Apenas manter conex√£o viva
        }
      } catch (error) {
        console.warn('‚ö†Ô∏è Erro ao processar mensagem SSE:', error)
      }
    }

    eventSource.onerror = (error) => {
      console.error('‚ùå Erro no SSE:', error)
      setRealtimeConnected(false)
      
      // Reconectar automaticamente ap√≥s 3 segundos
      if (eventSource.readyState === EventSource.CLOSED) {
        setTimeout(() => {
          if (isConnected && !isReconnectingRef.current) {
            console.log('üîÑ Tentando reconectar SSE...')
            isReconnectingRef.current = true
            connectSSE()
            isReconnectingRef.current = false
          }
        }, 3000)
      }
    }
  }, [config.consultationId, addFinalSegment, setRealtimeConnected, isConnected])

  // Desconectar do SSE
  const disconnectSSE = useCallback(() => {
    if (eventSourceRef.current) {
      console.log('üîå Desconectando SSE')
      eventSourceRef.current.close()
      eventSourceRef.current = null
      setRealtimeConnected(false)
    }
  }, [setRealtimeConnected])

  // Configurar grava√ß√£o para um microfone espec√≠fico
  const setupMicrophoneRecording = useCallback(async (
    deviceId: string, 
    speaker: 'doctor' | 'patient'
  ): Promise<MediaStream | null> => {
    try {
      console.log(`üé§ Configurando microfone ${speaker}:`, deviceId)
      
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          deviceId: { exact: deviceId },
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: false, // Desabilitar AGC para evitar "inventar" voz do ru√≠do
          sampleRate: 16000, // Reduzir para 16kHz para economizar banda
          channelCount: 1
        }
      })

      // Usar MediaRecorder nativo para capturar √°udio em formato WebM
      console.log(`üé§ Configurando MediaRecorder para ${speaker}`)
      
      // Verificar se MediaRecorder √© suportado
      if (!window.MediaRecorder) {
        throw new Error('MediaRecorder n√£o √© suportado neste navegador')
      }
      
      // Configurar MediaRecorder para capturar em chunks com fallbacks
      let mimeType = 'audio/webm;codecs=opus'
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = 'audio/webm'
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = 'audio/mp4'
          if (!MediaRecorder.isTypeSupported(mimeType)) {
            mimeType = 'audio/wav'
            if (!MediaRecorder.isTypeSupported(mimeType)) {
              // Usar o primeiro tipo suportado
              const supportedTypes = [
                'audio/webm;codecs=opus',
                'audio/webm',
                'audio/mp4',
                'audio/wav',
                'audio/ogg'
              ]
              mimeType = supportedTypes.find(type => MediaRecorder.isTypeSupported(type)) || ''
            }
          }
        }
      }
      
      console.log(`üéµ Usando MIME type: ${mimeType} para ${speaker}`)
      
      let mediaRecorder: MediaRecorder
      try {
        mediaRecorder = new MediaRecorder(stream, {
          mimeType
        })
      } catch (recorderError) {
        console.warn(`‚ö†Ô∏è Erro ao criar MediaRecorder com configura√ß√µes espec√≠ficas para ${speaker}, tentando configura√ß√£o b√°sica:`, recorderError)
        // Tentar sem configura√ß√µes espec√≠ficas
        mediaRecorder = new MediaRecorder(stream)
      }
      
      const chunksRef = speaker === 'doctor' ? doctorChunksRef : patientChunksRef
      const recorderRef = speaker === 'doctor' ? doctorRecorderRef : patientRecorderRef
      const intervalRef = speaker === 'doctor' ? doctorIntervalRef : patientIntervalRef
      
      recorderRef.current = mediaRecorder
      chunksRef.current = []

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data)
        }
      }

      mediaRecorder.onstop = async () => {
        if (chunksRef.current.length > 0 && !processingRef.current[speaker]) {
          const audioBlob = new Blob(chunksRef.current, { type: mimeType })
          await processAudioChunk(audioBlob, speaker)
          chunksRef.current = []
        }
      }

      // Iniciar grava√ß√£o em chunks de 3 segundos
      mediaRecorder.start()
      intervalRef.current = setInterval(() => {
        if (mediaRecorder.state === 'recording') {
          mediaRecorder.stop()
          setTimeout(() => {
            if (mediaRecorder.state === 'inactive') {
              mediaRecorder.start()
            }
          }, 100)
        }
      }, 3000)

      console.log(`‚úÖ Microfone ${speaker} configurado com sucesso`)
      return stream

    } catch (error) {
      console.error(`‚ùå Erro ao configurar microfone ${speaker}:`, error)
      setError(`Erro ao acessar microfone do ${speaker}`)
      return null
    }
  }, [])

  // Fun√ß√£o sendSpeechSegment removida - usando MediaRecorder nativo agora

  // Conectar ao LiveKit e iniciar transcri√ß√£o
  const connect = useCallback(async () => {
    if (isConnecting || isConnected) {
      console.log('‚ö†Ô∏è LiveKit j√° est√° conectando ou conectado')
      return
    }

    // Permitir conex√£o com pelo menos um microfone
    if (!doctorMic && !patientMic) {
      setError('Selecione pelo menos um microfone (m√©dico ou paciente)')
      return
    }
    
    // Avisar se apenas um microfone est√° selecionado
    if (!doctorMic || !patientMic) {
      const missingMic = !doctorMic ? 'm√©dico' : 'paciente'
      console.warn(`‚ö†Ô∏è Apenas microfone do ${missingMic === 'm√©dico' ? 'paciente' : 'm√©dico'} selecionado. Funcionando em modo single-mic.`)
    }

    try {
      setIsConnecting(true)
      setError(null)
      console.log('üîó Conectando ao LiveKit com dois microfones...', config)

      // 0. Carregar dispositivos dispon√≠veis
      await loadDevices()

      // 1. Obter token do LiveKit
      const tokenResponse = await fetch('/api/livekit/token', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          consultationId: config.consultationId,
          participantName: 'dual-mic-system',
          role: 'doctor'
        })
      })

      if (!tokenResponse.ok) {
        throw new Error('Erro ao obter token LiveKit')
      }

      const { token, mock } = await tokenResponse.json()

      if (mock) {
        console.warn('‚ö†Ô∏è Usando token mock - LiveKit n√£o configurado')
        setError('LiveKit n√£o configurado, usando modo fallback')
        setIsConnecting(false)
        return
      }

      // 2. Conectar √† sala LiveKit
      const room = new Room()
      roomRef.current = room

      // Configurar eventos da sala
      room.on(RoomEvent.Connected, async () => {
        console.log('‚úÖ Conectado ao LiveKit')
        setIsConnected(true)
        setIsConnecting(false)
        setRealtimeConnected(true)
        
        // Configurar microfones dispon√≠veis
        console.log('üé§ Configurando microfones...')
        
        const streams = []
        const participants = []
        
        // Configurar microfone do m√©dico se dispon√≠vel
        if (doctorMic) {
          console.log('üé§ Configurando microfone do m√©dico...')
          const doctorStream = await setupMicrophoneRecording(doctorMic, 'doctor')
          if (doctorStream) {
            doctorStreamRef.current = doctorStream
            streams.push(doctorStream)
            participants.push('doctor')
            console.log('‚úÖ Microfone do m√©dico configurado')
          }
        }
        
        // Configurar microfone do paciente se dispon√≠vel
        if (patientMic) {
          console.log('üé§ Configurando microfone do paciente...')
          const patientStream = await setupMicrophoneRecording(patientMic, 'patient')
          if (patientStream) {
            patientStreamRef.current = patientStream
            streams.push(patientStream)
            participants.push('patient')
            console.log('‚úÖ Microfone do paciente configurado')
          }
        }
        
        // Verificar se pelo menos um microfone foi configurado
        if (streams.length === 0) {
          throw new Error('Nenhum microfone p√¥de ser configurado')
        }
        
        console.log(`‚úÖ ${streams.length} microfone(s) configurado(s): ${participants.join(', ')}`)
        
        // Atualizar lista de participantes
        setParticipants(participants)
        // Conectar SSE ap√≥s LiveKit conectado
        connectSSE()
      })

      room.on(RoomEvent.Disconnected, () => {
        console.log('üîå Desconectado do LiveKit')
        setIsConnected(false)
        setRealtimeConnected(false)
        setParticipants([])
      })

      // Conectar √† sala
      const livekitUrl = config.livekitUrl || process.env.NEXT_PUBLIC_LIVEKIT_URL || 'wss://medtutor-5b3jl6hp.livekit.cloud'
      await room.connect(livekitUrl, token)

      // 3. Conectar ao stream de transcri√ß√µes em tempo real
      console.log('üîÑ Configurando stream de transcri√ß√µes...')
      
      const eventSource = new EventSource(
        `/api/transcriptions/stream?consultationId=${config.consultationId}`
      )
      eventSourceRef.current = eventSource

      eventSource.onopen = () => {
        console.log('‚úÖ Conectado ao stream de transcri√ß√µes')
        console.log('üîó SSE URL:', eventSource.url)
        console.log('üîó SSE readyState:', eventSource.readyState)
      }

      eventSource.onmessage = (event) => {
        // Mensagem SSE recebida
        try {
          const data = JSON.parse(event.data)
          // Dados SSE parseados
          
          if (data.type === 'transcription') {
            // Transcri√ß√£o recebida via SSE
            
            // Filtrar textos repetitivos e autom√°ticos
            if (isRepetitiveText(data.text)) {
              // Texto repetitivo filtrado
              return
            }
            
            // Verificar se √© muito similar √† √∫ltima transcri√ß√£o
            const lastSpeakerText = lastTranscriptionRef.current[data.speaker as 'doctor' | 'patient']
            if (lastSpeakerText && isSimilarTranscription(data.text, lastSpeakerText)) {
              // Texto similar filtrado
              return
            }
            
            // Atualizar √∫ltima transcri√ß√£o
            lastTranscriptionRef.current[data.speaker as 'doctor' | 'patient'] = data.text
            
            // Atualizar UI em tempo real com informa√ß√£o do speaker
            addFinalSegment({
              text: data.text,
              startMs: data.timestamp - 3000,
              endMs: data.timestamp,
              confidence: data.confidence || 0.8,
              isPartial: false,
              speaker: data.speaker // Incluir informa√ß√£o do speaker
            })
          }
        } catch (error) {
          console.warn('‚ö†Ô∏è Erro ao processar mensagem SSE:', error)
        }
      }

      eventSource.onerror = (error) => {
        console.error('‚ùå Erro no stream de transcri√ß√µes:', error)
        console.error('‚ùå SSE readyState:', eventSource.readyState)
        console.error('‚ùå SSE url:', eventSource.url)
        // Tentar reconectar ap√≥s 5 segundos
        if (!isReconnectingRef.current) {
          isReconnectingRef.current = true
          reconnectTimeoutRef.current = setTimeout(() => {
            console.log('üîÑ Tentando reconectar stream de transcri√ß√µes...')
            if (eventSourceRef.current) {
              eventSourceRef.current.close()
            }
            // Reconectar
            const newEventSource = new EventSource(
              `/api/transcriptions/stream?consultationId=${config.consultationId}`
            )
            eventSourceRef.current = newEventSource
            isReconnectingRef.current = false
          }, 5000)
        }
      }

    } catch (error) {
      console.error('‚ùå Erro ao conectar LiveKit:', error)
      setError(error instanceof Error ? error.message : 'Erro desconhecido')
      setIsConnecting(false)
      setRealtimeConnected(false)
    }
  }, [config, isConnecting, isConnected, doctorMic, patientMic, loadDevices, setupMicrophoneRecording, addFinalSegment, setRealtimeConnected])

  // Desconectar
  const disconnect = useCallback(() => {
    console.log('üîå Desconectando LiveKit...')
    
    // Limpar timeouts
    if (reconnectTimeoutRef.current) {
      clearTimeout(reconnectTimeoutRef.current)
      reconnectTimeoutRef.current = null
    }
    
    // Limpar transcri√ß√µes processadas
    processedTranscriptionsRef.current.clear()
    lastTranscriptionRef.current = { doctor: '', patient: '' }
    
    if (doctorIntervalRef.current) {
      clearInterval(doctorIntervalRef.current)
      doctorIntervalRef.current = null
    }
    
    if (patientIntervalRef.current) {
      clearInterval(patientIntervalRef.current)
      patientIntervalRef.current = null
    }
    
    // Desconectar VAD nodes
    if (doctorVADRef.current) {
      doctorVADRef.current.disconnect()
      doctorVADRef.current = null
    }
    if (patientVADRef.current) {
      patientVADRef.current.disconnect()
      patientVADRef.current = null
    }

    // Fechar AudioContexts
    if (doctorAudioContextRef.current) {
      doctorAudioContextRef.current.close()
      doctorAudioContextRef.current = null
    }
    if (patientAudioContextRef.current) {
      patientAudioContextRef.current.close()
      patientAudioContextRef.current = null
    }

    // Reset segmenters
    if (doctorSegmenterRef.current) {
      doctorSegmenterRef.current.reset()
      doctorSegmenterRef.current = null
    }
    if (patientSegmenterRef.current) {
      patientSegmenterRef.current.reset()
      patientSegmenterRef.current = null
    }
    
    // Parar streams
    if (doctorStreamRef.current) {
      doctorStreamRef.current.getTracks().forEach(track => track.stop())
      doctorStreamRef.current = null
    }
    
    if (patientStreamRef.current) {
      patientStreamRef.current.getTracks().forEach(track => track.stop())
      patientStreamRef.current = null
    }
    
    // Fechar EventSource
    if (eventSourceRef.current) {
      eventSourceRef.current.close()
      eventSourceRef.current = null
    }
    
    // Desconectar da sala
    if (roomRef.current) {
      roomRef.current.disconnect()
      roomRef.current = null
    }
    
    // Reset flags
    isReconnectingRef.current = false
    processingRef.current = { doctor: false, patient: false }
    
    setIsConnected(false)
    setIsConnecting(false)
    setRealtimeConnected(false)
    setParticipants([])
    setError(null)
    
  }, [setRealtimeConnected])

  // Monitor de atividade - verificar se a transcri√ß√£o parou
  useEffect(() => {
    if (!isConnected) return

    const activityCheck = setInterval(() => {
      const timeSinceLastActivity = Date.now() - lastActivityRef.current
      
      // Se n√£o houve atividade por mais de 30 segundos, tentar reconectar
      if (timeSinceLastActivity > 30000 && !isReconnectingRef.current) {
        console.warn('‚ö†Ô∏è Nenhuma atividade detectada por 30s, verificando conex√£o...')
        
        // Verificar se o EventSource ainda est√° conectado
        if (eventSourceRef.current && eventSourceRef.current.readyState === EventSource.CLOSED) {
          console.log('üîÑ EventSource fechado, reconectando...')
          isReconnectingRef.current = true
          
          if (eventSourceRef.current) {
            eventSourceRef.current.close()
          }
          
          const newEventSource = new EventSource(
            `/api/transcriptions/stream?consultationId=${config.consultationId}`
          )
          eventSourceRef.current = newEventSource
          isReconnectingRef.current = false
        }
      }
    }, 10000) // Verificar a cada 10 segundos

    return () => clearInterval(activityCheck)
  }, [isConnected, config.consultationId])

  // Cleanup no unmount
  useEffect(() => {
    return () => {
      disconnect()
    }
  }, [disconnect])

  return {
    connect,
    disconnect,
    isConnected,
    isConnecting,
    error,
    participants,
    devices,
    doctorMic,
    patientMic,
    setDoctorMic,
    setPatientMic,
    loadDevices,
    isSupported: () => typeof window !== 'undefined' && 'MediaRecorder' in window
  }
}
