import { useCallback, useRef, useState, useEffect } from 'react'
import { Room, RoomEvent, Track, LocalAudioTrack } from 'livekit-client'
import { useRecordingStore } from '../store/recording-store'

interface DualLiveKitSTTConfig {
  consultationId: string
  livekitUrl?: string
}

type DeviceOption = { deviceId: string; label: string }

type MicrophoneConfig = {
  deviceId: string
  speaker: 'doctor' | 'patient'
  label: string
}

export function useDualLivekitSTT(config: DualLiveKitSTTConfig) {
  const [isConnected, setIsConnected] = useState(false)
  const [isConnecting, setIsConnecting] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [participants, setParticipants] = useState<string[]>([])
  const [devices, setDevices] = useState<DeviceOption[]>([])
  const [doctorMic, setDoctorMic] = useState<string>('')
  const [patientMic, setPatientMic] = useState<string>('')
  
  const roomRef = useRef<Room | null>(null)
  const eventSourceRef = useRef<EventSource | null>(null)
  const doctorRecorderRef = useRef<MediaRecorder | null>(null)
  const patientRecorderRef = useRef<MediaRecorder | null>(null)
  const doctorChunksRef = useRef<Blob[]>([])
  const patientChunksRef = useRef<Blob[]>([])
  const processingRef = useRef<{ doctor: boolean; patient: boolean }>({ doctor: false, patient: false })
  const reconnectTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const doctorIntervalRef = useRef<NodeJS.Timeout | null>(null)
  const patientIntervalRef = useRef<NodeJS.Timeout | null>(null)
  const lastActivityRef = useRef<number>(Date.now())
  const isReconnectingRef = useRef(false)
  const doctorStreamRef = useRef<MediaStream | null>(null)
  const patientStreamRef = useRef<MediaStream | null>(null)
  
  const { 
    addFinalSegment, 
    setRealtimeConnected,
    setConsultationId 
  } = useRecordingStore()

  // Carregar dispositivos de áudio disponíveis
  const loadDevices = useCallback(async () => {
    try {
      console.log('🎤 Carregando dispositivos de áudio...')
      
      // Solicitar permissão primeiro
      await navigator.mediaDevices.getUserMedia({ audio: true })
      
      const deviceList = await navigator.mediaDevices.enumerateDevices()
      const microphones = deviceList
        .filter(device => device.kind === 'audioinput')
        .map(device => ({
          deviceId: device.deviceId,
          label: device.label || `Microfone ${device.deviceId.substring(0, 8)}`
        }))
      
      setDevices(microphones)
      console.log('🎤 Dispositivos encontrados:', microphones.length)
      
      // Definir dispositivos padrão se não houver seleção
      if (!doctorMic && microphones.length > 0) {
        setDoctorMic(microphones[0].deviceId)
        console.log('🩺 Microfone padrão do médico:', microphones[0].label)
      }
      
      if (!patientMic && microphones.length > 1) {
        setPatientMic(microphones[1].deviceId)
        console.log('🧑‍⚕️ Microfone padrão do paciente:', microphones[1].label)
      } else if (!patientMic && microphones.length === 1) {
        // Se só há um microfone, usar o mesmo para ambos (com processamento diferente)
        setPatientMic(microphones[0].deviceId)
        console.log('⚠️ Usando mesmo microfone para ambos (será separado por volume)')
      }
      
      return microphones
    } catch (error) {
      console.error('❌ Erro ao carregar dispositivos:', error)
      setError('Erro ao acessar dispositivos de áudio')
      return []
    }
  }, [doctorMic, patientMic])

  // Processar chunk de áudio para transcrição
  const processAudioChunk = useCallback(async (audioBlob: Blob, speaker: 'doctor' | 'patient') => {
    if (processingRef.current[speaker] || audioBlob.size < 1000) {
      return // Pular se já está processando ou chunk muito pequeno
    }

    try {
      processingRef.current[speaker] = true
      lastActivityRef.current = Date.now() // Atualizar atividade
      
      console.log(`🔄 Enviando chunk ${speaker} para transcrição:`, { 
        size: audioBlob.size, 
        speaker,
        consultationId: config.consultationId 
      })

      // Enviar para API de transcrição real com timeout
      const formData = new FormData()
      formData.append('audio', audioBlob, 'audio.webm')
      formData.append('speaker', speaker)
      formData.append('consultationId', config.consultationId)

      const controller = new AbortController()
      const timeoutId = setTimeout(() => controller.abort(), 10000) // 10s timeout

      try {
        const response = await fetch('/api/transcribe', {
          method: 'POST',
          body: formData,
          signal: controller.signal
        })

        clearTimeout(timeoutId)

        if (response.ok) {
          const result = await response.json()
          console.log(`✅ Transcrição ${speaker} recebida:`, result)
          
          if (result.text && result.text.trim()) {
            console.log(`📝 Transcrição ${speaker} processada:`, result.text)
          }
        } else {
          console.error(`❌ Erro na API de transcrição ${speaker}:`, response.status)
        }
      } catch (fetchError) {
        clearTimeout(timeoutId)
        if (fetchError instanceof Error && fetchError.name === 'AbortError') {
          console.warn(`⏰ Timeout na transcrição ${speaker}, tentando novamente...`)
        } else {
          throw fetchError
        }
      }

    } catch (error) {
      console.error(`❌ Erro ao processar chunk de áudio ${speaker}:`, error)
    } finally {
      processingRef.current[speaker] = false
    }
  }, [config.consultationId])

  // Conectar ao SSE para receber transcrições em tempo real
  const connectSSE = useCallback(() => {
    if (eventSourceRef.current) {
      console.log('⚠️ SSE já conectado')
      return
    }

    console.log('🔄 Conectando ao SSE para transcrições em tempo real...')
    
    const eventSource = new EventSource(`/api/transcriptions/stream?consultationId=${config.consultationId}`)
    eventSourceRef.current = eventSource

    eventSource.onopen = () => {
      console.log('✅ SSE conectado')
      setRealtimeConnected(true)
      lastActivityRef.current = Date.now()
    }

    eventSource.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data)
        lastActivityRef.current = Date.now()

        if (data.type === 'transcription') {
          console.log(`📝 Transcrição recebida via SSE (${data.speaker}):`, data.text)
          
          // Adicionar segmento final ao store com informação do speaker
          addFinalSegment({
            text: data.text,
            startMs: 0,
            endMs: 3000, // 3 segundos por chunk
            confidence: data.confidence,
            isPartial: false,
            speaker: data.speaker // Incluir informação do speaker
          })
        } else if (data.type === 'connected') {
          console.log('🔗 SSE conectado para consulta:', data.consultationId)
        } else if (data.type === 'heartbeat') {
          // Apenas manter conexão viva
        }
      } catch (error) {
        console.warn('⚠️ Erro ao processar mensagem SSE:', error)
      }
    }

    eventSource.onerror = (error) => {
      console.error('❌ Erro no SSE:', error)
      setRealtimeConnected(false)
      
      // Reconectar automaticamente após 3 segundos
      if (eventSource.readyState === EventSource.CLOSED) {
        setTimeout(() => {
          if (isConnected && !isReconnectingRef.current) {
            console.log('🔄 Tentando reconectar SSE...')
            isReconnectingRef.current = true
            connectSSE()
            isReconnectingRef.current = false
          }
        }, 3000)
      }
    }
  }, [config.consultationId, addFinalSegment, setRealtimeConnected, isConnected])

  // Desconectar do SSE
  const disconnectSSE = useCallback(() => {
    if (eventSourceRef.current) {
      console.log('🔌 Desconectando SSE')
      eventSourceRef.current.close()
      eventSourceRef.current = null
      setRealtimeConnected(false)
    }
  }, [setRealtimeConnected])

  // Configurar gravação para um microfone específico
  const setupMicrophoneRecording = useCallback(async (
    deviceId: string, 
    speaker: 'doctor' | 'patient'
  ): Promise<MediaStream | null> => {
    try {
      console.log(`🎤 Configurando microfone ${speaker}:`, deviceId)
      
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          deviceId: { exact: deviceId },
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 48000,
          channelCount: 1
        }
      })

      // Configurar MediaRecorder para capturar em chunks
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      })
      
      const chunksRef = speaker === 'doctor' ? doctorChunksRef : patientChunksRef
      const recorderRef = speaker === 'doctor' ? doctorRecorderRef : patientRecorderRef
      const intervalRef = speaker === 'doctor' ? doctorIntervalRef : patientIntervalRef
      
      recorderRef.current = mediaRecorder
      chunksRef.current = []

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data)
        }
      }

      mediaRecorder.onstop = async () => {
        if (chunksRef.current.length > 0 && !processingRef.current[speaker]) {
          const audioBlob = new Blob(chunksRef.current, { type: 'audio/webm' })
          await processAudioChunk(audioBlob, speaker)
          chunksRef.current = []
        }
      }

      // Iniciar gravação em chunks de 3 segundos
      mediaRecorder.start()
      intervalRef.current = setInterval(() => {
        if (mediaRecorder.state === 'recording') {
          mediaRecorder.stop()
          setTimeout(() => {
            if (mediaRecorder.state === 'inactive') {
              mediaRecorder.start()
            }
          }, 100)
        }
      }, 3000)

      console.log(`✅ Microfone ${speaker} configurado com sucesso`)
      return stream

    } catch (error) {
      console.error(`❌ Erro ao configurar microfone ${speaker}:`, error)
      setError(`Erro ao acessar microfone do ${speaker}`)
      return null
    }
  }, [processAudioChunk])

  // Conectar ao LiveKit e iniciar transcrição
  const connect = useCallback(async () => {
    if (isConnecting || isConnected) {
      console.log('⚠️ LiveKit já está conectando ou conectado')
      return
    }

    if (!doctorMic || !patientMic) {
      setError('Selecione os microfones do médico e paciente')
      return
    }

    try {
      setIsConnecting(true)
      setError(null)
      console.log('🔗 Conectando ao LiveKit com dois microfones...', config)

      // 0. Carregar dispositivos disponíveis
      await loadDevices()

      // 1. Obter token do LiveKit
      const tokenResponse = await fetch('/api/livekit/token', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          consultationId: config.consultationId,
          participantName: 'dual-mic-system',
          role: 'doctor'
        })
      })

      if (!tokenResponse.ok) {
        throw new Error('Erro ao obter token LiveKit')
      }

      const { token, mock } = await tokenResponse.json()

      if (mock) {
        console.warn('⚠️ Usando token mock - LiveKit não configurado')
        setError('LiveKit não configurado, usando modo fallback')
        setIsConnecting(false)
        return
      }

      // 2. Conectar à sala LiveKit
      const room = new Room()
      roomRef.current = room

      // Configurar eventos da sala
      room.on(RoomEvent.Connected, async () => {
        console.log('✅ Conectado ao LiveKit')
        setIsConnected(true)
        setIsConnecting(false)
        setRealtimeConnected(true)
        
        // Configurar ambos os microfones
        console.log('🎤 Configurando microfones simultâneos...')
        
        const doctorStream = await setupMicrophoneRecording(doctorMic, 'doctor')
        const patientStream = await setupMicrophoneRecording(patientMic, 'patient')
        
        if (doctorStream) {
          doctorStreamRef.current = doctorStream
        }
        
        if (patientStream) {
          patientStreamRef.current = patientStream
        }
        
        // Atualizar lista de participantes
        setParticipants(['doctor', 'patient'])
      })

      room.on(RoomEvent.Disconnected, () => {
        console.log('🔌 Desconectado do LiveKit')
        setIsConnected(false)
        setRealtimeConnected(false)
        setParticipants([])
      })

      // Conectar à sala
      const livekitUrl = config.livekitUrl || process.env.NEXT_PUBLIC_LIVEKIT_URL || 'wss://localhost:7880'
      await room.connect(livekitUrl, token)

      // 3. Conectar ao stream de transcrições em tempo real
      console.log('🔄 Configurando stream de transcrições...')
      
      const eventSource = new EventSource(
        `/api/transcriptions/stream?consultationId=${config.consultationId}`
      )
      eventSourceRef.current = eventSource

      eventSource.onopen = () => {
        console.log('✅ Conectado ao stream de transcrições')
        console.log('🔗 SSE URL:', eventSource.url)
        console.log('🔗 SSE readyState:', eventSource.readyState)
      }

      eventSource.onmessage = (event) => {
        console.log('📨 Mensagem SSE recebida:', event.data)
        try {
          const data = JSON.parse(event.data)
          console.log('📨 Dados SSE parseados:', data)
          
          if (data.type === 'transcription') {
            console.log('📨 Transcrição recebida via SSE:', data)
            console.log('🏪 Debug addFinalSegment:', data.text, data.speaker)
            
            // Atualizar UI em tempo real com informação do speaker
            addFinalSegment({
              text: data.text,
              startMs: data.timestamp - 3000,
              endMs: data.timestamp,
              confidence: data.confidence || 0.8,
              isPartial: false,
              speaker: data.speaker // Incluir informação do speaker
            })
          }
        } catch (error) {
          console.warn('⚠️ Erro ao processar mensagem SSE:', error)
        }
      }

      eventSource.onerror = (error) => {
        console.error('❌ Erro no stream de transcrições:', error)
        console.error('❌ SSE readyState:', eventSource.readyState)
        console.error('❌ SSE url:', eventSource.url)
        // Tentar reconectar após 5 segundos
        if (!isReconnectingRef.current) {
          isReconnectingRef.current = true
          reconnectTimeoutRef.current = setTimeout(() => {
            console.log('🔄 Tentando reconectar stream de transcrições...')
            if (eventSourceRef.current) {
              eventSourceRef.current.close()
            }
            // Reconectar
            const newEventSource = new EventSource(
              `/api/transcriptions/stream?consultationId=${config.consultationId}`
            )
            eventSourceRef.current = newEventSource
            isReconnectingRef.current = false
          }, 5000)
        }
      }

    } catch (error) {
      console.error('❌ Erro ao conectar LiveKit:', error)
      setError(error instanceof Error ? error.message : 'Erro desconhecido')
      setIsConnecting(false)
      setRealtimeConnected(false)
    }
  }, [config, isConnecting, isConnected, doctorMic, patientMic, loadDevices, setupMicrophoneRecording, addFinalSegment, setRealtimeConnected])

  // Desconectar
  const disconnect = useCallback(() => {
    console.log('🔌 Desconectando LiveKit...')
    
    // Limpar timeouts
    if (reconnectTimeoutRef.current) {
      clearTimeout(reconnectTimeoutRef.current)
      reconnectTimeoutRef.current = null
    }
    
    if (doctorIntervalRef.current) {
      clearInterval(doctorIntervalRef.current)
      doctorIntervalRef.current = null
    }
    
    if (patientIntervalRef.current) {
      clearInterval(patientIntervalRef.current)
      patientIntervalRef.current = null
    }
    
    // Parar MediaRecorders
    if (doctorRecorderRef.current && doctorRecorderRef.current.state !== 'inactive') {
      doctorRecorderRef.current.stop()
    }
    
    if (patientRecorderRef.current && patientRecorderRef.current.state !== 'inactive') {
      patientRecorderRef.current.stop()
    }
    
    // Parar streams
    if (doctorStreamRef.current) {
      doctorStreamRef.current.getTracks().forEach(track => track.stop())
      doctorStreamRef.current = null
    }
    
    if (patientStreamRef.current) {
      patientStreamRef.current.getTracks().forEach(track => track.stop())
      patientStreamRef.current = null
    }
    
    // Fechar EventSource
    if (eventSourceRef.current) {
      eventSourceRef.current.close()
      eventSourceRef.current = null
    }
    
    // Desconectar da sala
    if (roomRef.current) {
      roomRef.current.disconnect()
      roomRef.current = null
    }
    
    // Reset flags
    isReconnectingRef.current = false
    processingRef.current = { doctor: false, patient: false }
    
    setIsConnected(false)
    setIsConnecting(false)
    setRealtimeConnected(false)
    setParticipants([])
    setError(null)
    
  }, [setRealtimeConnected])

  // Monitor de atividade - verificar se a transcrição parou
  useEffect(() => {
    if (!isConnected) return

    const activityCheck = setInterval(() => {
      const timeSinceLastActivity = Date.now() - lastActivityRef.current
      
      // Se não houve atividade por mais de 30 segundos, tentar reconectar
      if (timeSinceLastActivity > 30000 && !isReconnectingRef.current) {
        console.warn('⚠️ Nenhuma atividade detectada por 30s, verificando conexão...')
        
        // Verificar se o EventSource ainda está conectado
        if (eventSourceRef.current && eventSourceRef.current.readyState === EventSource.CLOSED) {
          console.log('🔄 EventSource fechado, reconectando...')
          isReconnectingRef.current = true
          
          if (eventSourceRef.current) {
            eventSourceRef.current.close()
          }
          
          const newEventSource = new EventSource(
            `/api/transcriptions/stream?consultationId=${config.consultationId}`
          )
          eventSourceRef.current = newEventSource
          isReconnectingRef.current = false
        }
      }
    }, 10000) // Verificar a cada 10 segundos

    return () => clearInterval(activityCheck)
  }, [isConnected, config.consultationId])

  // Cleanup no unmount
  useEffect(() => {
    return () => {
      disconnect()
    }
  }, [disconnect])

  return {
    connect,
    disconnect,
    isConnected,
    isConnecting,
    error,
    participants,
    devices,
    doctorMic,
    patientMic,
    setDoctorMic,
    setPatientMic,
    loadDevices,
    isSupported: () => typeof window !== 'undefined' && 'MediaRecorder' in window
  }
}
